==============
MOM6 Internals
==============

:author: Marshall Ward
:description: Tour of MOM6 architecture
:date: 2022-10-18
:url: https://marshallward.org/mom6workshop/internals.html
:preface:
   TODO


MOM6 directory tree
===================

===============   =================================
Directory         Description
===============   =================================
``src/``          Model code, including solvers
``config_src/``   Configurable components
``pkg/``          Dependencies linked into ``src/``
``doc/``          Documentation
``ac/``           Autoconf build
===============   =================================


``config_src/drivers``
======================

===================     =========================
Directory               Driver
===================     =========================
``solo_driver``         Ocean-only
``ice_solo_driver``     Ice-ocean (MOM6-SIS2)
``FMS_cap``             GFDL (FMS) coupler
``nuopc_cap``           NUOPC coupler (CESM, UFS)
``mct_cap``             MCT coupler
===================     =========================

New coupled models would be expected to develop their own drivers.


Other configs
=============

``config_src/memory``
   Symmetric, Non-symmetric, static (presented later)

``config_src/infra``
   FMS1, FMS2

``config_src/external``
   BGC, Data assimilation, Python interface, etc.

Complex projects can add their own implementations

.. TODO example?  cheng's builds?


``src/``
========

======================  ============================
Directory               Description
======================  ============================
``core/``               Init, time-step, solvers
``parameterizations/``  Viscosity, mixing, diabatic
``tracer/``             Tracer dynamics
``ALE/``                Vertical remapping
``diagnostics/``        Diagonostic management
``user/``               Preset forcing, topography
======================  ============================

Also see ``framework/``, ``equation_of_state/``, etc


Module Format
=============

.. include:: doc/MOM_geothermal.F90
   :code: fortran

* One module per file
* Modules communicate by **control structures**
* No internal module variables (i.e. no "state")

.. notes::

   One consequence of having no state is that functions have many, many
   arguments.  An object-oriented approach could help reduce this.


Main Loop
=========

``step_MOM()``

==============    ============================
Process           Subroutine
================  ============================
Fluid Transport   ``step_MOM_dynamics()``
Diabatic forcing  ``step_MOM_thermo()``
Tracers           ``step_MOM_tracer_dyn()``
================  ============================

Ordering is somewhat configurable


"Outer" Dynamic core
====================

``step_MOM_dynamics()``

===================  ============================
Process              Subroutine
===================  ============================
GM, Redi diffusion   ``thickness_diffuse()``
Bottom drag          ``set_viscous_BBL()``
Flow transport       ``step_MOM_dyn_split_RK2()``
ML restratification  ``mixedlayer_restrat()``
Mesoscale eddies     ``step_forward_MEKE()``
===================  ============================

.. notes::

   Most ocean-specific parameterizations appear here


"Inner" Dynamic Core
====================

``step_MOM_dyn_split_RK2()``

===================================    ==========================
Process                                Subroutine
===================================    ==========================
:math:`f \hat{z} \times \mathbf{u}`    ``CorAdCalc()``
:math:`-\nabla p`                      ``PressureForce()``
Vertical Viscosity                     ``vertvisc()``
Barotropic steps                       ``btstep()``
Mass/Volume Balance                    ``continuity()``
Horizontal viscosity                   ``horizontal_viscosity()``
===================================    ==========================

.. notes::

   This repeats in a predictor/corrector-like algorithm.


Diabatic Forcing
================

``src/paramerizations/vertical/MOM_diabatic_driver.F90``

Many parameterizations are applied via ``diabatic()``

* Geothermal heating
* KPP (vertical) mixing
* Bulk mixed layer
* Convective mixing (CVMix)
* Shortwave radiative heating

If ``adiabatic()``, comparatively little happens here

.. notes::

   There are two diabatic functions: diabatic_ALE() and layered_diabatic()
   (actually two ALE functions!  But nevermind that)


Tracers
=======

* advect_tracer
* tracer_hordiff
* update_segment_tracer_reservoirs
* step_forward_meke


Metric Grids
============

.. image:: img/Arakawa_C_grid.png

:math:`(i,j)` follows the "northeast convention"


Memory Layout
=============

.. list-table::

   * - Symmetric:

       .. figure:: img/Horizontal_NE_indexing_sym.png


     - Nonsymmetric:

       .. figure:: img/Horizontal_NE_indexing_nonsym.png

* Symmetric grids have additional west/south points

* Index values unchanged (but symmetric B-grid is zero-indexed)

.. notes::

   If periodic, they match the east/north points


Index Macros
============

Static memory is supported with macros

``#include <MOM_memory.h>``

==========  ==================================
Field       Declaration
==========  ==================================
Center      ``h(SZI_(G), SZJ_(G), SZK_(G))``
East Face   ``u(SZIB_(G), SZJ_(G), SZK_(G))``
North Face  ``v(SZI_(G), SZJB_(G), SZK_(G))``
Vertex      ``q(SZIB_(G), SZJB_(G), SZK_(G))``
==========  ==================================

Use ``ALLOCABLE_()`` to allocate


Parallelization
===============

.. image:: img/halo.svg

MOM is single-pass: 4 sides and 4 corners concurrently

(Other models are two-pass: N/S then E/W)


Stencil Domains
===============

.. list-table::

   * - .. image:: img/Horizontal_NE_indexing_sym.png

     - Compute Domain
         Physical values

       Data Domain
         Include halos

       Global Domain
         Global indexing


Index Bounds
============

Bounds stored in ``ocean_grid_type``, ``G``

.. code::

   do j = G%jsc, G%jec
     do i = G%isc, G%iec
       h(i,j) = ...
     enddo
   enddo

Bounds may extend into halos (e.g. derivatives)


Message Passing
===============

``create_group_pass(group, array, domain)``
   Create a "group pass" for an array

``do_group_pass(group, domain)``
   Immediately update the halo ("blocking")

``start_group_pass(group, domain)``
   Begin a halo update ("nonblocking")

``complete_group_pass(group, domain)``
   Wait until a halo update has completed


Example halo update
===================

.. code:: fortran

   call create_group_pass(CS%pass_uv, u, v, G%Domain, &
                          halo=max(2,cont_stencil))

   u(:,:,:) = ...        ! Update compute domains
   v(:,:,:) = ...

   if (G%nonblocking_updates) &
      call start_group_pass(CS%pass_uv, G%Domain, clock=id_clock_pass)

   ! Do some work unrelated to u and v

   if (G%nonblocking_updates) then
     call complete_group_pass(CS%pass_uv, G%Domain, clock=id_clock_pass)
   else
     call do_group_pass(CS%pass_uv, G%Domain, clock=id_clock_pass)
   endif


.. Masking
   =======

   TODO


Diagnostics
===========

``register_diag_field()``

.. code:: fortran

   CS%id_Kh_h = register_diag_field('ocean_model', 'Khh', &
      diag%axesTL, Time, &
      'Laplacian Horizontal Viscosity at h Points', &
      'm2 s-1', &
      conversion=(US%L_to_m**2)*US%s_to_T)

``post_data()``

.. code:: fortran

   if (CS%id_Kh_h > 0) call post_data(CS%id_Kh_h, Kh_h, CS%diag)


Input Parameters
================

Define ``MOM_input`` parameters with ``get_param()``:

.. code:: fortran

   call get_param(param_file, mdl, "KH", Kh, &
                  "The background Laplacian horizontal viscosity", &
                  units="m2 s-1", &
                  default=0.0, &
                  scale=(US%m_to_L**2)*US%T_to_s, &
                  do_not_log=.not.CS%Laplacian &
   )


Checksums
=========

Verify the reproducibility of fields:

==============    ============
Field position    Checksum
==============    ============
Center            ``hchksum``
Face              ``uvchksum``
Vertex            ``Bchksum``
==============    ============

.. code:: fortran

   call hchksum(Kh_h, "Kh_h", G%HI, scale=(US%L_to_m**2)*US%s_to_T)

   call uvchksum("Kh_[uv]", Kh_u, Kh_v, G%HI, &
                 scale=(US%L_to_m**2)*US%s_to_T, scalar_pair=.true.)

   call Bchksum(Kh_q, "Kh_q", G%HI, scale=(US%L_to_m**2)*US%s_to_T)


.. Sample debug output
   -------------------

   TODO


Timers
======



Summary
=======

???
